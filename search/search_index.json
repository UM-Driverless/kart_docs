{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"KART Documentation","text":""},{"location":"#general-description","title":"General Description","text":"<p>This project equips a standard competition kart with autonomous capabilities by integrating perception, control, and actuation systems. It serves as a modular platform for rapid development and testing of driverless technologies in outdoor environments.</p>"},{"location":"#motivation","title":"Motivation","text":"<p>In Driverless, our objective is to enable a single-seater vehicle to autonomously navigate a circuit delimited by cones.</p> <p>Until now, teachers and researchers lacked a practical outdoor testbed for their algorithms. This year, Henakart donated a kart chassis, which we\u2019re converting to electric and equipping with autonomous systems. It\u2019s simpler and safer than the Formula car, making it ideal for early development and testing.</p>"},{"location":"#objectives","title":"Objectives","text":"<ul> <li>Build a modular testbed for autonomous driving components (perception, planning, control).</li> <li>Enable outdoor algorithm validation for students, teachers, and researchers.</li> <li>Reuse and adapt developed components for the single-seater Formula vehicle.</li> <li>Maintain manual drive capability for supervised operation and data collection.</li> </ul> <p>We are currently migrating from a Python-based stack to a ROS-based architecture to ensure compatibility with more complex vehicle platforms.</p>"},{"location":"#current-status-2025-06-18","title":"Current Status (2025-06-18)","text":"<ul> <li>The kart is fully operational in manual mode.</li> <li>Actuation systems for steering and braking are ordered.</li> <li>An emergency brake and telemetry system are in development.</li> <li>The camera used for cone detection is mounted.</li> <li>Work is ongoing to improve cone detection accuracy and software speed.</li> </ul>"},{"location":"#regulatory-requirements-and-limitations","title":"Regulatory Requirements and Limitations","text":"<p>This prototype is not intended to compete, so no specific racing regulations apply. Development follows general safety and engineering standards, and deviations are documented. Manual driving must be preserved. Standard kart components are preferred; custom parts are used only when justified.</p>"},{"location":"contact/","title":"Contact","text":"<p>You can reach the \u00dc Motorsport Formula Student team via email at marketingumotorsport@gmail.com.</p> <p>Our workshop is located at \u00dc\u2011Motorsport \u2013 C. del Molino, S/N, 28943 Fuenlabrada, Madrid (40.280670, -3.822346).</p> <p>Our website: https://u-motorsport.urjc.es/</p> <p>Social media - Instagram - LinkedIn - TikTok - X - Facebook</p>"},{"location":"faq/","title":"Frequently Asked Questions","text":""},{"location":"faq/#emergency-braking-system","title":"Emergency Braking System","text":""},{"location":"faq/#why-are-you-using-a-pneumatic-actuator-for-the-braking-system","title":"Why are you using a pneumatic actuator for the braking system?","text":"<p>If we need a force of 100\u202fkgf at a speed of 0.5\u202fm/s the power requirement is roughly 500\u202fW. An electric actuator capable of that is bulky and hard to source. A cable and pulley system with a motor and pressure feedback was considered, but cables cannot bend sharply. Since we already have a pneumatic piston from our sponsor Festo, it is the simplest solution.</p>"},{"location":"faq/#battery","title":"Battery","text":""},{"location":"faq/#why-is-the-battery-placed-at-the-back","title":"Why is the battery placed at the back?","text":"<p>The rear of the kart offered the most practical space for such a large and heavy component. Because the seat, wheels and pedals remain in their original positions, placing the pack behind the driver was the best compromise. Handling is less of a concern since the kart will usually run autonomously without a driver's weight.</p>"},{"location":"faq/#motor-choice","title":"Motor choice","text":""},{"location":"faq/#why-not-use-a-thermal-engine","title":"Why not use a thermal engine?","text":"<p>A combustion engine would add unnecessary complexity such as fuel, exhaust and cooling. Electric motors require little maintenance and are simpler to control electronically. Since this prototype focuses on sensors, actuators and software, the type of engine does not matter as long as the vehicle moves when throttle is applied.</p>"},{"location":"hardware/battery/","title":"Battery","text":"<p>To charge the battery with a bench power supply, see this tutorial: C\u00f3mo Cargar una Bater\u00eda de Litio con una Fuente</p> <p>The main pack uses Molicel P42A cells in a 13S4P configuration, providing a nominal voltage of about 48\u202fV. A separate 12\u202fV car battery supplies the sensors to remain compatible with the Formula Student car.</p> <p>For battery placement rationale see the FAQ.</p> Parameter Value BMS Cutoff voltage 39.0 V (13 * 3.0V) Configuration 13S4P (13 cells in series, 4 in parallel) Nominal voltage 48\u202fV Maximum charging voltage 54.6 V (13 * 4.2V) Minimum voltage 41.6 V (13 * 3.2V) Power Capacity 808 Wh (3.7V * 4.2 Ah * 13 * 4) Charge capacity 16.8 Ah (4 * 4200 mAh) Maximum continuous discharge current 180 A (4 * 45 A. 9828W at 100% charge!!) Maximum continuous charge current 32 A (4 * 8 A. about 1.7kW) Cell type Molicel P42A Cell capacity 4200 mAh (4.2 Ah) Cell nominal voltage 3.7 V Cell maximum voltage 4.2 V Cell minimum voltage 3.2 V"},{"location":"hardware/battery/#bms","title":"BMS","text":"<ul> <li>Jiabaida BMS,\u00a0100A BT UART,\u00a0NMC 6S-21S</li> <li>https://www.notion.so/BMS-Bater-a-Kart-JBD-16078747314380e68688c3ab787fc1f7?pvs=21</li> <li>https://es.aliexpress.com/item/1005007223779359.html </li> <li></li> </ul>"},{"location":"hardware/blue-pill/","title":"Blue Pill (STM32F103C6T6)","text":"<p>The Blue Pill is a small development board based on the STM32F103C6T6 microcontroller, which features an ARM Cortex-M3 core. It's a popular choice for hobbyists and professionals due to its low cost and powerful capabilities.</p>"},{"location":"hardware/blue-pill/#key-features-of-stm32f103c6t6","title":"Key Features of STM32F103C6T6","text":"<ul> <li>Core: ARM 32-bit Cortex-M3 CPU</li> <li>Clock Speed: Up to 72 MHz</li> <li>Flash Memory: 32 KB</li> <li>SRAM: 10 KB</li> <li>GPIOs: 37</li> <li>ADCs: 10-channel, 12-bit</li> <li>Timers: 3 general-purpose timers, 1 advanced-control timer</li> <li>Communication Interfaces: I2C, SPI, USART, USB, CAN</li> <li></li> </ul>"},{"location":"hardware/blue-pill/#pin-use","title":"Pin use","text":"Pin Name Physical Chip pin Function PA10 31 RXD for debugging PA9 30 TXD for debugging PA0 10 PWM output to H-bridge, 0-3.3V PA1 11 DIR, gpio output, either high (3.3V) or low (0V) for the turn direction of the steering motor PB6 42 SCL I2C input at 3.3V, from the Hall effect sensor of steering column PB7 43 SDA I2C input at 3.3V, from the Hall effect sensor of steering column TODO input target angle from Orin TODO CAN TX TODO CAN RX"},{"location":"hardware/camera/","title":"Camera","text":""},{"location":"hardware/camera/#zed2-camera-integration-documentation","title":"ZED2 Camera Integration Documentation","text":""},{"location":"hardware/camera/#overview","title":"Overview","text":"<p>This document describes the integration of the ZED2 stereo camera into the kart, its usage through the ROS 2 wrapper, and the combination with YOLOv5 for cone detection. </p>"},{"location":"hardware/camera/#official-resources","title":"Official Resources","text":"<ul> <li>ZED2 Camera Overview: https://www.stereolabs.com/zed-2/</li> <li>ZED ROS 2 Wrapper Documentation: https://docs.stereolabs.com/ros2/</li> </ul>"},{"location":"hardware/camera/#hardware-zed2-camera","title":"Hardware: ZED2 Camera","text":"<p>The ZED2 camera by Stereolabs is a stereo vision camera capable of providing:</p> <ul> <li>High-definition left and right stereo images</li> <li>Depth sensing</li> <li>3D point clouds</li> <li>Positional tracking (6DoF)</li> <li>Integrated IMU sensors (accelerometer, gyroscope, magnetometer)</li> <li>Environmental sensors (barometer, temperature sensor)</li> </ul>"},{"location":"hardware/camera/#ros-2-integration","title":"ROS 2 Integration","text":"<p>The ZED2 camera is integrated into the project using the official Stereolabs ZED ROS 2 Wrapper:</p> <ul> <li>GitHub: https://github.com/stereolabs/zed-ros2-wrapper</li> </ul>"},{"location":"hardware/camera/#installation-requirements","title":"Installation Requirements","text":"<p>To properly install and run the ZED ROS 2 Wrapper with the ZED2 camera, you must ensure the following dependencies and system configuration are in place.</p> <ul> <li> <p>Operating System</p> <ul> <li>Ubuntu 24.04 LTS is the recommended version for this setup.</li> <li>Other Ubuntu versions may be used; however, note that dependencies such as CUDA, TensorRT, ROS2, and the ZED SDK may require different versions and additional compatibility testing.</li> </ul> </li> <li> <p>ROS 2 Jazzy</p> <ul> <li>Install ROS 2 Jazzy by following the official instructions here: https://docs.ros.org/en/jazzy/Installation/Ubuntu-Install-Debs.html</li> </ul> </li> <li> <p>CUDA Toolkit (12.0 to 12.9)</p> <ul> <li>Install CUDA 12.x (any version from 12.0 to 12.9 is compatible).</li> <li>Download from the official NVIDIA website: https://developer.nvidia.com/cuda-downloads</li> </ul> </li> <li> <p>ZED SDK (v5.0)</p> <ul> <li>Download and install ZED SDK v5.0 for Ubuntu 24.04 with CUDA 12 and TensorRT 10 from the official release page: https://www.stereolabs.com/en-es/developers/release/5.0#82af3640d775</li> </ul> </li> <li> <p>TensorRT 10</p> <ul> <li>Download the TensorRT 10 <code>.deb</code> package for Ubuntu 24.04 + CUDA 12.9 from the official NVIDIA repository: https://developer.nvidia.com/downloads/compute/machine-learning/tensorrt/10.10.0/local_repo/nv-tensorrt-local-repo-ubuntu2404-10.10.0-cuda-12.9_1.0-1_amd64.deb</li> </ul> <p>After downloading the <code>.deb</code> file, run the following commands to install it:</p> </li> </ul> <pre><code>sudo dpkg -i nv-tensorrt-local-repo-ubuntu2404-10.10.0-cuda-12.9_1.0-1_amd64.deb\nsudo apt update\n</code></pre> <p>If you encounter GPG key errors, follow these additional steps:</p> <pre><code>sudo cp /var/nv-tensorrt-local-repo-ubuntu2404-10.10.0-cuda-12.9/*.gpg /usr/share/keyrings/\n\nsudo nano /etc/apt/sources.list.d/nv-tensorrt-local-repo-ubuntu2404-10.10.0-cuda-12.9.list\n</code></pre> <p>Replace the content of the file with:</p> <pre><code>deb [signed-by=/usr/share/keyrings/nv-tensorrt-local-CD20EDBE-keyring.gpg] file:///var/nv-tensorrt-local-repo-ubuntu2404-10.10.0-cuda-12.9 /\n</code></pre> <p>Then update again:</p> <pre><code>sudo apt update\n</code></pre> <p>This should resolve the key issues.</p> <p>Finally, install the required TensorRT runtime libraries:</p> <pre><code>sudo apt-get install libnvinfer10 libnvinfer-dev libnvinfer-plugin-dev python3-libnvinfer\n</code></pre> <ul> <li> <p>ZED ROS 2 Wrapper</p> <ul> <li>Clone and build the zed-ros2-wrapper package in your existing ROS 2 workspace:</li> </ul> </li> </ul> <pre><code>cd ~/ros2_ws/src\ngit clone https://github.com/stereolabs/zed-ros2-wrapper.git\ncd ..\nrosdep install --from-paths src --ignore-src -r -y\ncolcon build --symlink-install\n</code></pre> <p>Official repository: https://github.com/stereolabs/zed-ros2-wrapper</p> <p>Once all the dependencies are installed and the wrapper is successfully built, you should be able to launch the ZED2 ROS 2 node without issues.</p>"},{"location":"hardware/camera/#launching-the-camera","title":"Launching the Camera","text":"<p>The camera is launched using a provided launch file, typically:</p> <pre><code>ros2 launch zed_wrapper zed_camera.launch.py camera_model:=zed2\n</code></pre>"},{"location":"hardware/camera/#cone-detection-with-yolov5","title":"Cone Detection with YOLOv5","text":"<p>In this project, YOLOv5 is used to perform real-time cone detection on images captured by the ZED2 camera. The ZED ROS 2 Wrapper supports custom object detection models through ONNX integration, allowing you to run your own trained detectors such as YOLOv5 directly on the GPU using TensorRT for real-time inference.</p>"},{"location":"hardware/camera/#exporting-and-using-a-custom-yolov5-model","title":"Exporting and Using a Custom YOLOv5 Model","text":"<p>If you have trained a YOLOv5 model (e.g., for cone detection), follow these steps to integrate it into the ZED wrapper:</p> <ol> <li>Export the model to ONNX format:    You can do this using PyTorch and the YOLOv5 export tools (e.g., <code>export.py</code> script from the YOLOv5 repository):</li> </ol> <p>This will generate a <code>.onnx</code> file.</p> <ol> <li>Enable object detection in the ZED wrapper by editing the configuration file:</li> </ol> <p>Open your <code>common_stereo.yaml</code> (located in your ROS 2 workspace, inside <code>zed-ros2-wrapper/zed_wrapper/config</code>), and modify or add the following lines:</p> <p><code>yaml    object_detection:         od_enabled: true          model: 'CUSTOM_YOLOLIKE_BOX_OBJECTS'         custom_onnx_file: '$path to model'</code></p>"},{"location":"hardware/camera/#first-time-optimization","title":"First-Time Optimization","text":"<p>The first time you launch the node with your custom ONNX model, TensorRT will optimize the model for inference, which may take additional time (several seconds to minutes depending on the system). Subsequent runs will be much faster, as the optimized engine will be cached and reused.</p> <p>Once all dependencies are correctly installed and the YOLOv5 model is configured, you should be able to run real-time object detection with the ZED2 camera using ROS 2.</p>"},{"location":"hardware/computer/","title":"Computer","text":"<p>Our computer is based on the NVidia Jetson Orin Development Kit.</p>"},{"location":"hardware/computer/#links","title":"Links","text":"<ul> <li>Main Nvidia Jetson AGX Orin page: https://developer.nvidia.com/embedded/learn/jetson-agx-orin-devkit-user-guide/developer_kit_layout.html</li> <li>Datasheets for NVidia Jetson Orin: https://developer.nvidia.com/embedded/downloads TODO link here to datasheets in the repo itself</li> </ul>"},{"location":"hardware/computer/#data","title":"Data","text":""},{"location":"hardware/computer/#power","title":"Power","text":"<ul> <li>Power consumption: </li> <li>Voltage range: 9-20VDC, typically 19V</li> <li>Power connector: Barrel Jack 5.5mm OD 2.5mm ID center positive</li> </ul>"},{"location":"hardware/computer/#specs","title":"Specs","text":"<p>TODO</p>"},{"location":"hardware/computer/#notes","title":"Notes","text":""},{"location":"hardware/computer/#how-to-install-anydesk-in-nvidia-jetson-orin","title":"How to install Anydesk in Nvidia Jetson Orin","text":"<pre><code>wget -qO - https://keys.anydesk.com/repos/DEB-GPG-KEY | sudo apt-key add -\necho 'deb http://deb.anydesk.com/ all main' | sudo tee /etc/apt/sources.list.d/anydesk.list\nsudo apt update                                                     \nsudo apt install -y anydesk\n</code></pre>"},{"location":"hardware/motor/","title":"Powertrain","text":""},{"location":"hardware/motor/#motor","title":"Motor","text":"<p>We use a BLDC motor from Kunray along with its supplied controller. The motivation for selecting an electric motor over a combustion engine is discussed in the FAQ.</p>"},{"location":"hardware/steering/","title":"Motor Data","text":"<p>24V motor, we will use it at 12V, estimated about 300W</p>"},{"location":"hardware/steering/#main-process","title":"Main process","text":"<p>We need to move the steering shaft to the target angle.</p> <ol> <li>Micro controller reads target position from main computer (Orin) and current position from the Hall effect sensor<ul> <li>Micro controller may be a Blue Pill, Teensy 4.0, or one with CAN transceiver builtin.</li> </ul> </li> <li>Calculates PWM % value with PID. Sends PWM 3.3V to H-bridge</li> <li>H-bridge (MD30C) receives PWM and powers the DC motor<ul> <li>ChatGpt said it can't work with 3.3V PWM, just 5V PWM, but the datasheet says otherwise here</li> </ul> </li> </ol>"},{"location":"hardware/steering/#h-bridge-data","title":"H-bridge data","text":"<p>See H-bridge for more details.</p>"},{"location":"hardware/steering/h-bridge/","title":"H-bridge data","text":"<ul> <li>Cytron MD30C (30\u202fA cont, 80\u202fA peak)  <ul> <li>https://www.cytron.io/p-30amp-5v-30v-dc-motor-driver </li> <li>Bought here to ship to Spain: https://opencircuit.es/producto/30amp-5v-30v-dc-motor-driver</li> <li>https://www.cytron.io/p-30amp-5v-30v-dc-motor-driver?srsltid=AfmBOoo-TCLyyRQ5SBEhwpIMcAhQIaXDzO-NgCP_LdYCx8KNeVAThvSF </li> <li>https://docs.google.com/document/d/178uDa3dmoG0ZX859rWUOS2Xyafkd8hSsSET5-ZLXMYQ/view </li> <li>https://github.com/CytronTechnologies/CytronMotorDriver</li> <li>https://www.cytron.io/tutorial/controlling-md10c-with-arduino</li> <li>https://www.instructables.com/Controlling-Motor-Speed/</li> </ul> </li> </ul>"},{"location":"hardware/steering/h-bridge/#reasoning","title":"Reasoning","text":"<p>Suggested H-bridges by gpt:</p> <ul> <li>Cytron MD30C (30\u202fA cont, 80\u202fA peak)  </li> <li>Pololu VNH5019 Driver (12\u202fA cont, 30\u202fA peak)  <ul> <li>https://www.pololu.com/product/1451?utm_source=chatgpt.com </li> </ul> </li> <li>~~Sabertooth 2x32: Overkill but excellent for dual motors, up to 32\u202fA per channel~~  </li> <li>~~Simple BTS7960: Cheap dual half-bridge module, supports 43\u202fA per channel, needs external PWM and logic control~~  </li> <li>~~IBT-4~~<ul> <li>Needs two synced pwm signals to control the H bridge, so it's harder to use. Otherwise it would work and it's cheaper</li> </ul> </li> </ul>"},{"location":"hardware/steering/sensor/","title":"Steering Angle Sensor","text":"<p>Sensor used is the cheap AS5600 </p> <p>Intended for use with a diametrically magnetized magnet, but works with a normal one turned 90 degrees too. It may be a good idea to find bigger neodymium diametric magnets.</p> <p>Repo with basic code to read the steering angle sensor (Arduino HAL with VSCode Platformio, no IDE): https://github.com/rubenayla/bluepill-angle-arduino.git</p> <p> </p>"},{"location":"hydraulics/","title":"Hydraulics","text":""},{"location":"hydraulics/#brake-pressure-sensor","title":"Brake Pressure Sensor","text":"<p>We are using flexible brake hoses with M10x1.0 female connectors. Our pressure sensor is the Sensata PTE7100, code <code>PTE7100-33CC-2E200BN</code>, datasheet here, mouser here.</p> <ul> <li>7/16-20 UNF-2A (MALE) pressure port</li> <li>Packard Metri-Pack 150 connector</li> <li>HNBR o-ring</li> <li>1-5Vdc/8-32Vdc</li> <li>0\u2013200 bar pressure range</li> <li>no mating connector or snubber</li> <li>To connect the sensor to the brake lines, we use a male M10x1.0 to female 1/4-18NPT adapter.</li> </ul> <p></p>"},{"location":"pneumatics/","title":"Pneumatics","text":"<p>We need an emergency braking system that can be activated on loss of electrical power or error from the shutdown loop, and a proportional braking system that can be controlled by the main computer when the robot is running.</p> <p>TODO redesign circuit with the valves we have, instead of using two different ones. </p> <p>TODO order components: proportional valve, adapters to have no problems using any of our tanks, pressure sensors, </p> <p>Original Idea: Use a ball valve to merge the proportional braking line with the emergency one, and an extra electrovalve to stop flow to the proportional valve when emergency.</p>"},{"location":"pneumatics/#simplified-design-todo-simulate-it","title":"Simplified design (TODO simulate it)","text":"<p>If the proportional valve does close both ways when not powered, we can get rid of the valve that goes in series with it. If we close port 3 of the emergency electrovalve, we can get rid of the valve with the ball at the top.</p> <p></p>"},{"location":"pneumatics/#components","title":"Components","text":"<ul> <li>Solenoid valve     &gt; For emergency braking<ul> <li>Datasheet local</li> <li>Datasheet online</li> <li>G1/4 female thread</li> </ul> </li> <li>Proportional Valve     &gt; For normal controlled braking<ul> <li>TODO CONSIDER AN 8-PIN M16 PROPORTIONAL VALVE SO WE CAN USE IT AS PRESSURE SENSOR</li> <li>Datasheet online</li> <li>Datasheet local</li> <li>206533 documentation</li> <li>TODO QUESTION: Can we get the reading of pressure from this valve? There are some that allow it</li> </ul> </li> <li>Fittings:<ul> <li>90\u00ba TODO what thread what size, what tube material and OD/ID.</li> <li>Straight TODO what adapters</li> </ul> </li> <li>Pressure sensor</li> </ul>"},{"location":"software/","title":"Software","text":"<p>The software documentation will include its own repository, since it must be common and independent from Kart or Formula Student car.</p> <ul> <li>2024 version of the software, using Python:<ul> <li>https://github.com/UM-Driverless/driverless.git</li> <li>Tutorial: https://youtu.be/wZSFr2eYE4M?si=K0gPpFHeWrK2Y9I8</li> </ul> </li> <li>2025 version of the software, using ROS:<ul> <li>https://github.com/UM-Driverless/KART_SW.git</li> <li>git@github.com:UM-Driverless/KART_SW.git</li> </ul> </li> <li></li> </ul>"},{"location":"wiring/","title":"Wiring","text":"<p>TODO: Add content</p>"}]}